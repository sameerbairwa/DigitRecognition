{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the dataset from the website Mnist\n",
    "import urllib\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "def load_dataset():\n",
    "    def download(filename, source=\"http://yann.lecun.com/exdb/mnist/\"):\n",
    "        print(\"Downloading...\", filename)\n",
    "        import urllib\n",
    "        urllib.request.urlretrieve(source+filename, filename)\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        with gzip.open(filename,'rb') as f:\n",
    "            #open the zip file of images\n",
    "            data = np.frombuffer(f.read(),np.uint8,offset=16)\n",
    "            #Each image has 28x28 pixels, its a monochrome image ie only 1 channel\n",
    "            #it were full-color it would have 3/4 channels R,G,B\n",
    "            data = data.reshape(-1, 1, 28, 28)\n",
    "            #the first dimension is the number of images, making this -1\n",
    "        return data/np.float32(256)\n",
    "        #this will convert the byte value to a float32 in the range[0,1]\n",
    "        \n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "            # Read the labels which are in a binary form\n",
    "        with gzip.open(filename,'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "                #this gives a numpy array of intergers, the digit value corresponding to the image\n",
    "        return data\n",
    "\n",
    "        #now we can download and read the training and test data sets\n",
    "    x_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    x_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg') # a Default setting for matplotlib for how to render images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show(plt.imshow(x_train[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name downsample",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9c149ec4fe63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Lasagne is a library that uses Theano heavily and supports building of neural networks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#it comes with functions to set up layers, define error functions train neural networks etc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\code-tech\\Anaconda3\\lib\\site-packages\\lasagne\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnonlinearities\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mobjectives\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\code-tech\\Anaconda3\\lib\\site-packages\\lasagne\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\code-tech\\Anaconda3\\lib\\site-packages\\lasagne\\layers\\pool.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mas_tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name downsample"
     ]
    }
   ],
   "source": [
    "#we are going to use 2 python packages called theano and lasagne\n",
    "#Theano is a mathematical packaege that allows you to define and \n",
    "#mathematical computations. - like numpy but with high dimensional arrays\n",
    "#Higher dimensional arrays are often called Tensors -  and Theano is a python package to work with them\n",
    "\n",
    "#Lasagne is a library that uses Theano heavily and supports building of neural networks.\n",
    "#it comes with functions to set up layers, define error functions train neural networks etc\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "def build_NN(imput_var = None):\n",
    "    #we are going to create a nueral network with 2 hidden layers of 800 each.\n",
    "    #the output layer will have 10 nodes - the nodes are numbered 0-9 and the outpu\n",
    "    #at each node will be a value between 0-1. The node with the highest value will be the predicted output\n",
    "    \n",
    "    #First we have an input layer - the expacted input shape is\n",
    "    #1x28x28 (for 1 image)\n",
    "    #We will link this input to the input_var (which will be the array of images that we'll pass in later on)\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None,1,28,28), input_var = input_var)\n",
    "    \n",
    "    #we'll add a 20% dropout - this means that randomly 20% of the edges between the \n",
    "    #inputs and the next layer will be dropped - this is done to avoid overfitting\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "    \n",
    "    #Add a layer with 800 nodes. Initially this  will be dense/fully-connected\n",
    "    #ie. every edge possible\n",
    "    #will be drawn.\n",
    "    l_hid1 = lasagne.layers.DenseLayer(l_in_drop, num_units = 800, \n",
    "                                       nonlinearity = lasagne.nonlinearities.rectify, \n",
    "                                       W = lasagne.init.GlorotUniform())\n",
    "    \n",
    "    #This layer has been initialized with some weights. There are some schemes to\n",
    "    #initialize the weights so that training will be done faster, Glorot's scheme\n",
    "    #is one of them\n",
    "    \n",
    "    #we will add a dropout of 50% to the hidden layer 1\n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p = 0.5)\n",
    "    \n",
    "    #Add another layere, it works exectly the same way\n",
    "    l_hid2 = lasagne.layers.DenseLayer(l_hid1_drop, num_units = 800, \n",
    "                                       nonlinearity = lasagne.nonlinearities.rectify, \n",
    "                                       W = lasagne.init.GlorotUniform())\n",
    "    \n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p = 0.5)\n",
    "    \n",
    "    # Let's now add the final output layer.\n",
    "    l_out = lasagne.layers.DenseLayer(l_hid2_drop, num_units = 10, \n",
    "                                       nonlinearity = lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    #the output layer has 10 units. softmax specifies that each of those\n",
    "    #output is between 0-1 and the max of the those will be the final prediction\n",
    "    \n",
    "    return l_out #we return the last layer, but since all the layers are linked\n",
    "#we effectivily return the whole network\n",
    "\n",
    "#We've setup the network. now we have to tell the network how to train itself\n",
    "#ie how should it find the values od all the weights it needs to find\n",
    "\n",
    "#We'll initialize some empty arrays which will act as placeholders\n",
    "#for the training/test data that will be given to the network\n",
    "\n",
    "input_var = T.tensor4('inputs') # An empty 4 demensional array\n",
    "target_var = T.ivector('targets') # An empty 1 dimensional integer array to represernt the lables\n",
    "\n",
    "network = build_NN(input_var) #call the fucntion that initialize the neural network\n",
    "\n",
    "#it training we are going to follow the steps blow\n",
    "#a. compute an error function\n",
    "\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "#catagorical cross entropy is one of the standard error fucntions with\n",
    "#classification problems\n",
    "loss = loss.mean()\n",
    "\n",
    "#b. We'll tell the network how to update all its weights based on the\n",
    "#value of the error fucntion\n",
    "params = lasagne.layers.get_all_params(network, trainable = True) #current value of all\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate = 0.01, momentum = 0.9)\n",
    "\n",
    "#Nestrov momemtum is one fo the options that lasagne offers for updating the weights\n",
    "#in a training step. this is based on Stochastic Gradient Descent - the idea is simple\n",
    "#Find the slope of the error function at the current point and move downwords\n",
    "#in the direction  of that slope\n",
    "\n",
    "#We'll use theano to compile a function that is going to represent a \n",
    "#single training step ie. compute the error, find the current weights, updates the weights\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "#calling this fucntion for a certain number of times will train the neural network\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4144357001008814\n",
      "2.39643881138562\n",
      "2.3714091236356394\n",
      "2.3470555912452604\n",
      "2.321185257914009\n",
      "2.2905010927613243\n",
      "2.2601833636570983\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-c505a30f317e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_training_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#print(\"Current step is \"+str(step))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\code-tech\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_storage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequired\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m                 \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[1;31m# if we are allowing garbage collection, remove the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_training_steps = 10 # Ideally you can train for a few 100 steps\n",
    "\n",
    "for step in range(num_training_steps):\n",
    "    train_err = train_fn(x_train, y_train)\n",
    "    #print(\"Current step is \"+str(step))\n",
    "    print(train_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05415224, 0.15168205, 0.04740196, 0.0617309 , 0.13617745,\n",
       "        0.1505447 , 0.16307532, 0.05555481, 0.14800482, 0.03167576]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the prediction for 1 image we'll need to set up another function\n",
    "test_prediction = lasagne.layers.get_output(network)\n",
    "val_fn = theano.function([input_var], test_prediction)\n",
    "\n",
    "val_fn([x_test[1]]) # This will apply the function on 1 image, the first one in the test set\n",
    "#The max value if for the digit 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the actual value\n",
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lasagne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a90f896494b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#feed the images to our network and compute it's accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#checks the index of the max value in each test prediction and matches it agains the actual value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lasagne' is not defined"
     ]
    }
   ],
   "source": [
    "#step 5: We'll feed a test data set of 10000 images to the trained neural network\n",
    "#and check it's accuracy\n",
    "\n",
    "#we'll set up a function that will take in a images and their lables,\n",
    "#feed the images to our network and compute it's accuracy\n",
    "\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var), dtype = theano.config.floatX)\n",
    "#checks the index of the max value in each test prediction and matches it agains the actual value\n",
    "acc_fn = theano.function([input_var,target_var],test_acc)\n",
    "\n",
    "acc_fn(x_test,y_test)\n",
    "#this is pretty poor accuracy \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
