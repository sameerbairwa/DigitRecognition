{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset \n",
    "import gzip\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "if sys.version_info < (3,):\n",
    "    data = pickle.load(f)\n",
    "else:\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "f.close()\n",
    "(X_train,y_train ), (X_test, y_test) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[5], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# CNN for the MNIST Dataset\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN model\n",
    "def build_NN():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.3657 - acc: 0.8875 - val_loss: 0.0755 - val_acc: 0.9768\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0908 - acc: 0.9724 - val_loss: 0.0426 - val_acc: 0.9862\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0666 - acc: 0.9791 - val_loss: 0.0344 - val_acc: 0.9886\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0563 - acc: 0.9827 - val_loss: 0.0310 - val_acc: 0.9897\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0464 - acc: 0.9855 - val_loss: 0.0339 - val_acc: 0.9888\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0421 - acc: 0.9864 - val_loss: 0.0271 - val_acc: 0.9917\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0381 - acc: 0.9875 - val_loss: 0.0260 - val_acc: 0.9928\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0338 - acc: 0.9891 - val_loss: 0.0282 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0312 - acc: 0.9897 - val_loss: 0.0255 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0237 - val_acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c100eeee10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model = build_NN()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Error: 0.74%\n",
      "Accuracy of CNN model < 99.26%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "print(\"Accuracy of CNN model < %.2f%%\" % (scores[1]*100))\n",
    "model.save('degit2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image digit is  7\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 1 channel\n",
    "    img = img.reshape(1,1, 28, 28)\n",
    "    # prepare pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "    # load the image\n",
    "    img = load_image('sample_image.png')\n",
    "    # load model\n",
    "    model = load_model('digit2_model.h5')\n",
    "    # predict the class\n",
    "    digit = model.predict_classes(img)\n",
    "    print(\"Image digit is \",digit[0])\n",
    "\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
